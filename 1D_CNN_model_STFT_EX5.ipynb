{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-27 03:51:59.380941: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import *\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/root/dataset/'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = os.getcwd() + \"/dataset/\"\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/dataset//train\n",
      "/root/dataset//val\n",
      "/root/dataset//test\n"
     ]
    }
   ],
   "source": [
    "TRAINING_DIR = path+\"/train\"\n",
    "VALIDATION_DIR = path + \"/val\"\n",
    "TEST_DIR = path + \"/test\"\n",
    "\n",
    "print(TRAINING_DIR)\n",
    "print(VALIDATION_DIR)\n",
    "print(TEST_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader(path):\n",
    "    X = []\n",
    "    Y = []\n",
    "    for folder in os.listdir(path):\n",
    "        for file in os.listdir(os.path.join(path, folder)):\n",
    "            feature = np.load(os.path.join(path, folder, file))\n",
    "            label = folder\n",
    "            X.append(feature)\n",
    "            Y.append(label)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = data_loader(TRAINING_DIR)\n",
    "X_val, Y_val = data_loader(VALIDATION_DIR)\n",
    "X_test, Y_test = data_loader(TEST_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 14000 training samples and 14000 training labels\n",
      "There are 2000 validation samples and 2000 validation labels\n",
      "There are 4000 testing samples and 4000 testing labels\n"
     ]
    }
   ],
   "source": [
    "print(\"There are {} training samples and {} training labels\".format(len(X_train), len(Y_train)))\n",
    "print(\"There are {} validation samples and {} validation labels\".format(len(X_val), len(Y_val)))\n",
    "print(\"There are {} testing samples and {} testing labels\".format(len(X_test), len(Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (14000, 64575)\n",
      "Shape of X_val: (2000, 64575)\n",
      "Shape of X_test: (4000, 64575)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.array(X_train)\n",
    "X_val = np.array(X_val)\n",
    "X_test = np.array(X_test)\n",
    "Y_train = np.array(Y_train)\n",
    "Y_val = np.array(Y_val)\n",
    "Y_test = np.array(Y_test)\n",
    "\n",
    "print(\"Shape of X_train: {}\".format(X_train.shape))\n",
    "print(\"Shape of X_val: {}\".format(X_val.shape))\n",
    "print(\"Shape of X_test: {}\".format(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (14000, 64575, 1)\n",
      "Shape of X_val: (2000, 64575, 1)\n",
      "Shape of X_test: (4000, 64575, 1)\n"
     ]
    }
   ],
   "source": [
    "# Reshape the input data\n",
    "X_train = X_train.reshape( (X_train.shape[0], X_train.shape[1], 1) )\n",
    "X_val = X_val.reshape( (X_val.shape[0], X_val.shape[1], 1) )\n",
    "X_test = X_test.reshape( (X_test.shape[0], X_test.shape[1], 1) )\n",
    "Y_train = Y_train.reshape( (Y_train.shape[0], 1) )\n",
    "Y_val = Y_val.reshape( (Y_val.shape[0], 1) )\n",
    "Y_test = Y_test.reshape( (Y_test.shape[0], 1) )\n",
    "\n",
    "print(\"Shape of X_train: {}\".format(X_train.shape))\n",
    "print(\"Shape of X_val: {}\".format(X_val.shape))\n",
    "print(\"Shape of X_test: {}\".format(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle the dataset\n",
    "shuffle_index = np.random.permutation(len(X_train))\n",
    "X_train, Y_train = X_train[shuffle_index], Y_train[shuffle_index]\n",
    "shuffle_index = np.random.permutation(len(X_val))\n",
    "X_val, Y_val = X_val[shuffle_index], Y_val[shuffle_index]\n",
    "shuffle_index = np.random.permutation(len(X_test))\n",
    "X_test, Y_test = X_test[shuffle_index], Y_test[shuffle_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "Y_train = label_encoder.fit_transform(Y_train)\n",
    "Y_val = label_encoder.fit_transform(Y_val)\n",
    "Y_test = label_encoder.fit_transform(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-27 03:52:09.088291: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22078 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:c1:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    layers.Input(shape=(X_train.shape[1:])),\n",
    "    layers.Conv1D(16, 3, activation='relu'),\n",
    "    layers.MaxPooling1D(2),\n",
    "    layers.Conv1D(32, 3, activation='relu'),\n",
    "    layers.MaxPooling1D(2),\n",
    "    layers.Conv1D(64, 3, activation='relu'),\n",
    "    layers.MaxPooling1D(2),\n",
    "    layers.Conv1D(128, 3, activation='relu'),\n",
    "    layers.MaxPooling1D(2),\n",
    "    layers.Conv1D(256, 3, activation='relu'),\n",
    "    layers.MaxPooling1D(2),\n",
    "    layers.Conv1D(512, 3, activation='relu'),\n",
    "    layers.MaxPooling1D(2),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(1024, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 64573, 16)         64        \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 32286, 16)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 32284, 32)         1568      \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 16142, 32)        0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 16140, 64)         6208      \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 8070, 64)         0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 8068, 128)         24704     \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (None, 4034, 128)        0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 4032, 256)         98560     \n",
      "                                                                 \n",
      " max_pooling1d_4 (MaxPooling  (None, 2016, 256)        0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 2014, 512)         393728    \n",
      "                                                                 \n",
      " max_pooling1d_5 (MaxPooling  (None, 1007, 512)        0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 515584)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              527959040 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               524800    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 529,009,185\n",
      "Trainable params: 529,009,185\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystopper = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=20,\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-27 03:52:09.797238: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 3616200000 exceeds 10% of free system memory.\n",
      "2023-06-27 03:52:11.447631: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 3616200000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-27 03:52:14.929121: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2023-06-27 03:52:16.297231: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-06-27 03:52:16.312834: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7fefa8017860 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-06-27 03:52:16.312892: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2023-06-27 03:52:16.321984: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-06-27 03:52:16.471642: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 32s 214ms/step - loss: 0.5592 - accuracy: 0.7030 - val_loss: 0.4756 - val_accuracy: 0.7855\n",
      "Epoch 2/120\n",
      "110/110 [==============================] - 19s 175ms/step - loss: 0.4369 - accuracy: 0.8007 - val_loss: 0.3806 - val_accuracy: 0.8255\n",
      "Epoch 3/120\n",
      "110/110 [==============================] - 19s 175ms/step - loss: 0.3667 - accuracy: 0.8314 - val_loss: 0.3296 - val_accuracy: 0.8435\n",
      "Epoch 4/120\n",
      "110/110 [==============================] - 19s 175ms/step - loss: 0.3259 - accuracy: 0.8559 - val_loss: 0.2837 - val_accuracy: 0.8760\n",
      "Epoch 5/120\n",
      "110/110 [==============================] - 19s 175ms/step - loss: 0.2789 - accuracy: 0.8748 - val_loss: 0.2672 - val_accuracy: 0.8835\n",
      "Epoch 6/120\n",
      "110/110 [==============================] - 19s 174ms/step - loss: 0.2470 - accuracy: 0.8929 - val_loss: 0.2370 - val_accuracy: 0.8965\n",
      "Epoch 7/120\n",
      "110/110 [==============================] - 19s 174ms/step - loss: 0.2201 - accuracy: 0.9039 - val_loss: 0.2142 - val_accuracy: 0.9140\n",
      "Epoch 8/120\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.2003 - accuracy: 0.9167 - val_loss: 0.2174 - val_accuracy: 0.9220\n",
      "Epoch 9/120\n",
      "110/110 [==============================] - 19s 175ms/step - loss: 0.1824 - accuracy: 0.9259 - val_loss: 0.1819 - val_accuracy: 0.9240\n",
      "Epoch 10/120\n",
      "110/110 [==============================] - 19s 175ms/step - loss: 0.1620 - accuracy: 0.9326 - val_loss: 0.1762 - val_accuracy: 0.9340\n",
      "Epoch 11/120\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1587 - accuracy: 0.9348 - val_loss: 0.1863 - val_accuracy: 0.9340\n",
      "Epoch 12/120\n",
      "110/110 [==============================] - 19s 175ms/step - loss: 0.1466 - accuracy: 0.9395 - val_loss: 0.1663 - val_accuracy: 0.9410\n",
      "Epoch 13/120\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1364 - accuracy: 0.9439 - val_loss: 0.1846 - val_accuracy: 0.9365\n",
      "Epoch 14/120\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1266 - accuracy: 0.9499 - val_loss: 0.1715 - val_accuracy: 0.9350\n",
      "Epoch 15/120\n",
      "110/110 [==============================] - 19s 175ms/step - loss: 0.1162 - accuracy: 0.9526 - val_loss: 0.1440 - val_accuracy: 0.9440\n",
      "Epoch 16/120\n",
      "110/110 [==============================] - 19s 175ms/step - loss: 0.1067 - accuracy: 0.9568 - val_loss: 0.1423 - val_accuracy: 0.9450\n",
      "Epoch 17/120\n",
      "110/110 [==============================] - 19s 175ms/step - loss: 0.1067 - accuracy: 0.9586 - val_loss: 0.1368 - val_accuracy: 0.9505\n",
      "Epoch 18/120\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0963 - accuracy: 0.9593 - val_loss: 0.1654 - val_accuracy: 0.9460\n",
      "Epoch 19/120\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0861 - accuracy: 0.9659 - val_loss: 0.1520 - val_accuracy: 0.9480\n",
      "Epoch 20/120\n",
      "110/110 [==============================] - 19s 175ms/step - loss: 0.0815 - accuracy: 0.9689 - val_loss: 0.1332 - val_accuracy: 0.9560\n",
      "Epoch 21/120\n",
      "110/110 [==============================] - 19s 175ms/step - loss: 0.0806 - accuracy: 0.9689 - val_loss: 0.1295 - val_accuracy: 0.9540\n",
      "Epoch 22/120\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0744 - accuracy: 0.9713 - val_loss: 0.1465 - val_accuracy: 0.9565\n",
      "Epoch 23/120\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0726 - accuracy: 0.9726 - val_loss: 0.1513 - val_accuracy: 0.9515\n",
      "Epoch 24/120\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0636 - accuracy: 0.9736 - val_loss: 0.1407 - val_accuracy: 0.9555\n",
      "Epoch 25/120\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0668 - accuracy: 0.9746 - val_loss: 0.1405 - val_accuracy: 0.9530\n",
      "Epoch 26/120\n",
      "110/110 [==============================] - 19s 175ms/step - loss: 0.0676 - accuracy: 0.9746 - val_loss: 0.1287 - val_accuracy: 0.9550\n",
      "Epoch 27/120\n",
      "110/110 [==============================] - 19s 175ms/step - loss: 0.0572 - accuracy: 0.9772 - val_loss: 0.1277 - val_accuracy: 0.9595\n",
      "Epoch 28/120\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0569 - accuracy: 0.9792 - val_loss: 0.1796 - val_accuracy: 0.9570\n",
      "Epoch 29/120\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0478 - accuracy: 0.9819 - val_loss: 0.1702 - val_accuracy: 0.9580\n",
      "Epoch 30/120\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0455 - accuracy: 0.9829 - val_loss: 0.1922 - val_accuracy: 0.9580\n",
      "Epoch 31/120\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0451 - accuracy: 0.9829 - val_loss: 0.1590 - val_accuracy: 0.9590\n",
      "Epoch 32/120\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0375 - accuracy: 0.9859 - val_loss: 0.1512 - val_accuracy: 0.9555\n",
      "Epoch 33/120\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0409 - accuracy: 0.9829 - val_loss: 0.1711 - val_accuracy: 0.9575\n",
      "Epoch 34/120\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0369 - accuracy: 0.9859 - val_loss: 0.2135 - val_accuracy: 0.9560\n",
      "Epoch 35/120\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0360 - accuracy: 0.9866 - val_loss: 0.1914 - val_accuracy: 0.9615\n",
      "Epoch 36/120\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0368 - accuracy: 0.9856 - val_loss: 0.1684 - val_accuracy: 0.9615\n",
      "Epoch 37/120\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0406 - accuracy: 0.9851 - val_loss: 0.2000 - val_accuracy: 0.9580\n",
      "Epoch 38/120\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0373 - accuracy: 0.9854 - val_loss: 0.1842 - val_accuracy: 0.9575\n",
      "Epoch 39/120\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0308 - accuracy: 0.9876 - val_loss: 0.1739 - val_accuracy: 0.9620\n",
      "Epoch 40/120\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0435 - accuracy: 0.9853 - val_loss: 0.1640 - val_accuracy: 0.9590\n",
      "Epoch 41/120\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0301 - accuracy: 0.9886 - val_loss: 0.1869 - val_accuracy: 0.9625\n",
      "Epoch 42/120\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0245 - accuracy: 0.9906 - val_loss: 0.1760 - val_accuracy: 0.9595\n",
      "Epoch 43/120\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0274 - accuracy: 0.9908 - val_loss: 0.1446 - val_accuracy: 0.9615\n",
      "Epoch 44/120\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0270 - accuracy: 0.9906 - val_loss: 0.1348 - val_accuracy: 0.9605\n",
      "Epoch 45/120\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0247 - accuracy: 0.9907 - val_loss: 0.1365 - val_accuracy: 0.9610\n",
      "Epoch 46/120\n",
      "110/110 [==============================] - 19s 176ms/step - loss: 0.0249 - accuracy: 0.9911 - val_loss: 0.1221 - val_accuracy: 0.9640\n",
      "Epoch 47/120\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0226 - accuracy: 0.9923 - val_loss: 0.1567 - val_accuracy: 0.9660\n",
      "Epoch 48/120\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0193 - accuracy: 0.9929 - val_loss: 0.1886 - val_accuracy: 0.9575\n",
      "Epoch 49/120\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0204 - accuracy: 0.9928 - val_loss: 0.1683 - val_accuracy: 0.9605\n",
      "Epoch 50/120\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0298 - accuracy: 0.9909 - val_loss: 0.1766 - val_accuracy: 0.9555\n",
      "Epoch 51/120\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0205 - accuracy: 0.9929 - val_loss: 0.1656 - val_accuracy: 0.9640\n",
      "Epoch 52/120\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0225 - accuracy: 0.9924 - val_loss: 0.1837 - val_accuracy: 0.9570\n",
      "Epoch 53/120\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0181 - accuracy: 0.9944 - val_loss: 0.1813 - val_accuracy: 0.9580\n",
      "Epoch 54/120\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0339 - accuracy: 0.9911 - val_loss: 0.1616 - val_accuracy: 0.9620\n",
      "Epoch 55/120\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0559 - accuracy: 0.9854 - val_loss: 0.1312 - val_accuracy: 0.9640\n",
      "Epoch 56/120\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0212 - accuracy: 0.9923 - val_loss: 0.1573 - val_accuracy: 0.9645\n",
      "Epoch 57/120\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0144 - accuracy: 0.9954 - val_loss: 0.1599 - val_accuracy: 0.9655\n",
      "Epoch 58/120\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0144 - accuracy: 0.9956 - val_loss: 0.1445 - val_accuracy: 0.9655\n",
      "Epoch 59/120\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0155 - accuracy: 0.9951 - val_loss: 0.1622 - val_accuracy: 0.9655\n",
      "Epoch 60/120\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0117 - accuracy: 0.9961 - val_loss: 0.1687 - val_accuracy: 0.9685\n",
      "Epoch 61/120\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0127 - accuracy: 0.9954 - val_loss: 0.1397 - val_accuracy: 0.9650\n",
      "Epoch 62/120\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0120 - accuracy: 0.9950 - val_loss: 0.2413 - val_accuracy: 0.9575\n",
      "Epoch 63/120\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0142 - accuracy: 0.9947 - val_loss: 0.1927 - val_accuracy: 0.9645\n",
      "Epoch 64/120\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0131 - accuracy: 0.9952 - val_loss: 0.2280 - val_accuracy: 0.9605\n",
      "Epoch 65/120\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0315 - accuracy: 0.9904 - val_loss: 0.1977 - val_accuracy: 0.9555\n",
      "Epoch 66/120\n",
      "110/110 [==============================] - 19s 173ms/step - loss: 0.0206 - accuracy: 0.9936 - val_loss: 0.2422 - val_accuracy: 0.9580\n",
      "Training completed in 1231 seconds.\n"
     ]
    }
   ],
   "source": [
    "epochs = 120\n",
    "batch_size = 128\n",
    "current_time = int(time.time())\n",
    "stop_training_callback = earlystopper\n",
    "history = model.fit(X_train, Y_train, \n",
    "                    epochs=epochs, \n",
    "                    batch_size=batch_size,\n",
    "                    validation_data=(X_val, Y_val), \n",
    "                    callbacks=[stop_training_callback])\n",
    "print(\"Training completed in {} seconds.\".format(int(time.time()-current_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc=history.history['accuracy']\n",
    "# val_acc=history.history['val_accuracy']\n",
    "# loss=history.history['loss']\n",
    "# val_loss=history.history['val_loss']\n",
    "\n",
    "# epochs=range(len(acc))\n",
    "\n",
    "# plt.plot(epochs, acc, 'r', \"Training Accuracy\")\n",
    "# plt.plot(epochs, val_acc, 'b', \"Validation Accuracy\")\n",
    "# plt.title('Training and validation accuracy')\n",
    "# plt.show()\n",
    "# print(\"\")\n",
    "\n",
    "# plt.plot(epochs, loss, 'r', \"Training Loss\")\n",
    "# plt.plot(epochs, val_loss, 'b', \"Validation Loss\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 2s 11ms/step\n"
     ]
    }
   ],
   "source": [
    "test_predict = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0\n",
      "0     1.0\n",
      "1     1.0\n",
      "2     0.0\n",
      "3     1.0\n",
      "4     0.0\n",
      "...   ...\n",
      "3995  1.0\n",
      "3996  1.0\n",
      "3997  1.0\n",
      "3998  0.0\n",
      "3999  1.0\n",
      "\n",
      "[4000 rows x 1 columns]\n",
      "4000\n"
     ]
    }
   ],
   "source": [
    "show_test_predict = np.round(test_predict, 0)\n",
    "show_test_predict = pd.DataFrame(show_test_predict)\n",
    "print(show_test_predict)\n",
    "print(len(show_test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import roc_curve, auc\n",
    "# fpr, tpr, thresholds = roc_curve(Y_test, test_predict)\n",
    "# roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# plt.figure()\n",
    "# plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)'% roc_auc)\n",
    "# plt.plot([0,1],[0,1], color='navy', lw=2, linestyle='--')\n",
    "# plt.xlim([0.0,1.0])\n",
    "# plt.ylim([0.0,1.05])\n",
    "# plt.xlabel(\"False Positive Rate\")\n",
    "# plt.ylabel(\"True Positive Rate\")\n",
    "# plt.title(\"ROC Curve\")\n",
    "# plt.legend(loc=\"lower right\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9637494902272064"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(Y_test, show_test_predict, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1920,   80],\n",
       "       [  65, 1935]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cf = confusion_matrix(Y_test, show_test_predict)\n",
    "display(cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 2s 13ms/step - loss: 0.1557 - accuracy: 0.9638\n"
     ]
    }
   ],
   "source": [
    "stt = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.15567752718925476, 0.9637500047683716]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(f\"1D_CNN_5ACC.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
