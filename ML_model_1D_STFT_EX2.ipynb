{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import *\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, BaggingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/root/dataset/'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = os.getcwd() + \"/dataset/\"\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/dataset//train\n",
      "/root/dataset//val\n",
      "/root/dataset//test\n"
     ]
    }
   ],
   "source": [
    "TRAINING_DIR = path+\"/train\"\n",
    "VALIDATION_DIR = path + \"/val\"\n",
    "TEST_DIR = path + \"/test\"\n",
    "\n",
    "print(TRAINING_DIR)\n",
    "print(VALIDATION_DIR)\n",
    "print(TEST_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader(path):\n",
    "    X = []\n",
    "    Y = []\n",
    "    for folder in os.listdir(path):\n",
    "        for file in os.listdir(os.path.join(path, folder)):\n",
    "            feature = np.load(os.path.join(path, folder, file))\n",
    "            label = folder\n",
    "            X.append(feature)\n",
    "            Y.append(label)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = data_loader(TRAINING_DIR)\n",
    "X_val, Y_val = data_loader(VALIDATION_DIR)\n",
    "X_test, Y_test = data_loader(TEST_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 14000 training samples and 14000 training labels\n",
      "There are 2000 validation samples and 2000 validation labels\n",
      "There are 4000 testing samples and 4000 testing labels\n"
     ]
    }
   ],
   "source": [
    "print(\"There are {} training samples and {} training labels\".format(len(X_train), len(Y_train)))\n",
    "print(\"There are {} validation samples and {} validation labels\".format(len(X_val), len(Y_val)))\n",
    "print(\"There are {} testing samples and {} testing labels\".format(len(X_test), len(Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (14000, 64575)\n",
      "Shape of X_val: (2000, 64575)\n",
      "Shape of X_test: (4000, 64575)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.array(X_train)\n",
    "X_val = np.array(X_val)\n",
    "X_test = np.array(X_test)\n",
    "Y_train = np.array(Y_train)\n",
    "Y_val = np.array(Y_val)\n",
    "Y_test = np.array(Y_test)\n",
    "\n",
    "print(\"Shape of X_train: {}\".format(X_train.shape))\n",
    "print(\"Shape of X_val: {}\".format(X_val.shape))\n",
    "print(\"Shape of X_test: {}\".format(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle the dataset\n",
    "shuffle_index = np.random.permutation(len(X_train))\n",
    "X_train, Y_train = X_train[shuffle_index], Y_train[shuffle_index]\n",
    "shuffle_index = np.random.permutation(len(X_val))\n",
    "X_val, Y_val = X_val[shuffle_index], Y_val[shuffle_index]\n",
    "shuffle_index = np.random.permutation(len(X_test))\n",
    "X_test, Y_test = X_test[shuffle_index], Y_test[shuffle_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "Y_train = label_encoder.fit_transform(Y_train)\n",
    "Y_val = label_encoder.fit_transform(Y_val)\n",
    "Y_test = label_encoder.fit_transform(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_training(model, X_train, Y_train, X_val, Y_val, X_test, Y_test):\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, Y_train)\n",
    "    time_taken = time.time() - start_time\n",
    "    Y_val_pred = model.predict(X_val)\n",
    "    Y_test_pred = model.predict(X_test)\n",
    "    val_acc = accuracy_score(Y_val, Y_val_pred)\n",
    "    test_acc = accuracy_score(Y_test, Y_test_pred)\n",
    "    recall_val = recall_score(Y_val, Y_val_pred, average='macro')\n",
    "    recall_test = recall_score(Y_test, Y_test_pred, average='macro')\n",
    "    precision_val = precision_score(Y_val, Y_val_pred, average='macro')\n",
    "    precision_test = precision_score(Y_test, Y_test_pred, average='macro')\n",
    "    f1_val = f1_score(Y_val, Y_val_pred, average='macro')\n",
    "    f1_test = f1_score(Y_test, Y_test_pred, average='macro')\n",
    "    conf_matrix_val = confusion_matrix(Y_val, Y_val_pred)\n",
    "    conf_matrix_test = confusion_matrix(Y_test, Y_test_pred)\n",
    "    print('We have used the following model: {}'.format(model))\n",
    "    print('Test Accuracy: {}'.format(test_acc))\n",
    "    print('F1 Score: {}'.format(f1_test))\n",
    "    print('Confusion Matrix: {}'.format(conf_matrix_test))\n",
    "    print('Time taken (seconds): {}'.format(round(time_taken, 2)))\n",
    "    return val_acc, test_acc, recall_val, recall_test, precision_val, precision_test, f1_val, f1_test, conf_matrix_val, conf_matrix_test, time_taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "resul = []\n",
    "model_names = ['Random Forest', 'KNN', 'MLP', 'Decision Tree', 'AdaBoost', 'Gradient Boosting', 'Extra Trees', 'Bagging', 'XGBoost']\n",
    "models = [RandomForestClassifier(), \n",
    "          KNeighborsClassifier(), MLPClassifier(), DecisionTreeClassifier(), AdaBoostClassifier(), GradientBoostingClassifier(), ExtraTreesClassifier(), BaggingClassifier(), XGBClassifier()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have used the following model: RandomForestClassifier()\n",
      "Test Accuracy: 0.84275\n",
      "F1 Score: 0.8427134210399806\n",
      "Confusion Matrix: [[1655  345]\n",
      " [ 284 1716]]\n",
      "Time taken (seconds): 452.12\n",
      "We have used the following model: KNeighborsClassifier()\n",
      "Test Accuracy: 0.85125\n",
      "F1 Score: 0.8510542760095687\n",
      "Confusion Matrix: [[1775  225]\n",
      " [ 370 1630]]\n",
      "Time taken (seconds): 0.41\n"
     ]
    }
   ],
   "source": [
    "for model, model_name in zip(models, model_names):\n",
    "    val_acc, test_acc, recall_val, recall_test, precision_val, precision_test, f1_val, f1_test, conf_matrix_val, conf_matrix_test, time_taken = model_training(model, X_train, Y_train, X_val, Y_val, X_test, Y_test)\n",
    "    resul.append({'Model': model_name, 'Validation Accuracy': val_acc, 'Test Accuracy': test_acc, 'Validation Recall': recall_val, 'Test Recall': recall_test, 'Validation Precision': precision_val, 'Test Precision': precision_test, 'Validation F1': f1_val, 'Test F1': f1_test, 'Validation Confusion Matrix': conf_matrix_val, 'Test Confusion Matrix': conf_matrix_test, 'Time Taken': time_taken})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(resul)\n",
    "result_df.to_csv('result_1D_STFT.csv', index=False)\n",
    "result_df.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without SVM, logistic, Gausian"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
